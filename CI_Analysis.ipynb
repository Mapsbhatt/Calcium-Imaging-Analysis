{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8953510",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e57b5c9",
   "metadata": {},
   "source": [
    "**Problem 1a**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886cb9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile as tiff\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "# Load the TIFF stack\n",
    "video_path = '/Users/mananbhatt/Downloads/TEST_MOVIE_00001-small-motion.tif'\n",
    "frames = tiff.imread(video_path)\n",
    "num_frames = frames.shape[0]\n",
    "\n",
    "print(f\"Loaded {num_frames} frames, each of shape {frames.shape[1:]}\")\n",
    "\n",
    "# Part A: Play the video using matplotlib animation\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(frames[0], cmap='gray', animated=True)\n",
    "\n",
    "def update(frame_idx):\n",
    "    im.set_array(frames[frame_idx])\n",
    "    ax.set_title(f\"Frame {frame_idx}\")\n",
    "    return [im]\n",
    "\n",
    "ani = animation.FuncAnimation(fig, update, frames=num_frames, interval=100, blit=True)\n",
    "\n",
    "# Display the animation in notebook\n",
    "mpl.rcParams['animation.embed_limit'] = 100  # allow bigger animations\n",
    "HTML(ani.to_jshtml())\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa2fe92",
   "metadata": {},
   "source": [
    "**Problem 1b**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d86688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "frame1 = frames[10]\n",
    "frame2 = frames[260]  # First drastic change observed\n",
    "\n",
    "# Normalize frames for correlation\n",
    "f1 = (frame1 - np.mean(frame1)) / np.std(frame1)\n",
    "f2 = (frame2 - np.mean(frame2)) / np.std(frame2)\n",
    "\n",
    "# Define max shift range\n",
    "max_shift = 10\n",
    "correlations = np.zeros((2 * max_shift + 1, 2 * max_shift + 1))\n",
    "\n",
    "# Compute correlation for each spatial shift\n",
    "for dx in range(-max_shift, max_shift + 1):\n",
    "    for dy in range(-max_shift, max_shift + 1):\n",
    "        shifted = scipy.ndimage.shift(f2, shift=(dy, dx), mode='nearest')\n",
    "        correlation = np.sum(f1 * shifted) / f1.size\n",
    "        correlations[dy + max_shift, dx + max_shift] = correlation\n",
    "\n",
    "# Find peak correlation shift\n",
    "peak = np.unravel_index(np.argmax(correlations), correlations.shape)\n",
    "peak_dy = peak[0] - max_shift\n",
    "peak_dx = peak[1] - max_shift\n",
    "print(f\"Maximum correlation at shift: dx={peak_dx}, dy={peak_dy}\")\n",
    "\n",
    "# Plot correlation heatmap\n",
    "plt.imshow(correlations, extent=[-max_shift, max_shift, -max_shift, max_shift], cmap='hot')\n",
    "plt.colorbar(label=\"Correlation\")\n",
    "plt.title(\"Correlation vs Spatial Shift\")\n",
    "plt.xlabel(\"X Shift\")\n",
    "plt.ylabel(\"Y Shift\")\n",
    "plt.annotate(f'Peak ({peak_dx},{peak_dy})', xy=(peak_dx, peak_dy), xytext=(peak_dx+1, peak_dy+1),\n",
    "             arrowprops=dict(arrowstyle='->'), color='white', fontsize=10)\n",
    "plt.scatter(peak_dx, peak_dy, color='blue', label=\"Peak\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6f9448",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Max correlation value:\", np.max(correlations))\n",
    "print(\"Correlation at peak (-2,2):\", correlations[peak[0], peak[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca9c98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "frame1 = frames[10]\n",
    "frame2 = frames[330]  # First drastic change observed\n",
    "\n",
    "# Normalize frames for correlation\n",
    "f1 = (frame1 - np.mean(frame1)) / np.std(frame1)\n",
    "f2 = (frame2 - np.mean(frame2)) / np.std(frame2)\n",
    "\n",
    "# Define max shift range\n",
    "max_shift = 10\n",
    "correlations = np.zeros((2 * max_shift + 1, 2 * max_shift + 1))\n",
    "\n",
    "# Compute correlation for each spatial shift\n",
    "for dx in range(-max_shift, max_shift + 1):\n",
    "    for dy in range(-max_shift, max_shift + 1):\n",
    "        shifted = scipy.ndimage.shift(f2, shift=(dy, dx), mode='nearest')\n",
    "        correlation = np.sum(f1 * shifted) / f1.size\n",
    "        correlations[dy + max_shift, dx + max_shift] = correlation\n",
    "\n",
    "# Find peak correlation shift\n",
    "peak = np.unravel_index(np.argmax(correlations), correlations.shape)\n",
    "peak_dy = peak[0] - max_shift\n",
    "peak_dx = peak[1] - max_shift\n",
    "print(f\"Maximum correlation at shift: dx={peak_dx}, dy={peak_dy}\")\n",
    "\n",
    "# Plot correlation heatmap\n",
    "plt.imshow(correlations, extent=[-max_shift, max_shift, -max_shift, max_shift], cmap='hot')\n",
    "plt.colorbar(label=\"Correlation\")\n",
    "plt.title(\"Correlation vs Spatial Shift\")\n",
    "plt.xlabel(\"X Shift\")\n",
    "plt.ylabel(\"Y Shift\")\n",
    "plt.annotate(f'Peak ({peak_dx},{peak_dy})', xy=(peak_dx, peak_dy), xytext=(peak_dx+1, peak_dy+1),\n",
    "             arrowprops=dict(arrowstyle='->'), color='white', fontsize=10)\n",
    "plt.scatter(peak_dx, peak_dy, color='blue', label=\"Peak\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"Max correlation value:\", np.max(correlations))\n",
    "print(\"Correlation at peak (0,1):\", correlations[peak[0], peak[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b297b71",
   "metadata": {},
   "source": [
    "**Problem 2a**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0899f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile as tiff\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the motion-corrected calcium image video\n",
    "file_path = '/Users/mananbhatt/Downloads/TEST_MOVIE_00001-small.tif'\n",
    "video = tiff.imread(file_path)\n",
    "\n",
    "print(f\"Video shape: {video.shape}  [frames, height, width]\")\n",
    "\n",
    "# Compute summary images\n",
    "mean_img = np.mean(video, axis=0)\n",
    "median_img = np.median(video, axis=0)\n",
    "var_img = np.var(video, axis=0)\n",
    "\n",
    "# Plot the images\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "axs[0].imshow(mean_img, cmap='plasma')\n",
    "axs[0].set_title('Mean Image')\n",
    "axs[0].axis('off')\n",
    "\n",
    "axs[1].imshow(median_img, cmap='plasma')\n",
    "axs[1].set_title('Median Image')\n",
    "axs[1].axis('off')\n",
    "\n",
    "axs[2].imshow(var_img, cmap='hot')\n",
    "axs[2].set_title('Variance Image')\n",
    "axs[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276ff915",
   "metadata": {},
   "source": [
    "**Answer**: \n",
    "**We computed summary images using the mean, median, and variance of pixel intensities across time. The mean image provides a general overview of fluorescence brightness but tends to blur out dynamic activity. The median image is ideally more robust to transient spikes and gives a cleaner view of consistently active regions. The variance image, in contrast, highlights pixels with high temporal fluctuation, making it effective at identifying neurons that exhibit strong activity over time.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af698853",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_img = mean_img - median_img  \n",
    "plt.imshow(diff_img, cmap='seismic')\n",
    "plt.title(\"Mean - Median\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840e7a26",
   "metadata": {},
   "source": [
    "**Answer**: \n",
    "**Since there wasn't a high visual difference between mean and median from the summary images. I experimented by plotting the change between the two sets. In such neurons, rare high-amplitude events increase the mean intensity while the median remains low. This contrast is visible in the form of bright white or red regions in the image. In contrast, neurons with consistent activity show little to no difference between their mean and median values and appear dark in this visualization.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24eebd97",
   "metadata": {},
   "source": [
    "**Problem 2b**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96add2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_img = np.max(video, axis=0) - np.min(video, axis=0)\n",
    "std_img = np.std(video, axis=0)\n",
    "\n",
    "# Plot additional stats\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "axs[0].imshow(range_img, cmap='inferno')\n",
    "axs[0].set_title('Max - Min (Range)')\n",
    "axs[0].axis('off')\n",
    "\n",
    "axs[1].imshow(std_img, cmap='plasma')\n",
    "axs[1].set_title('Standard Deviation')\n",
    "axs[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0f69ae",
   "metadata": {},
   "source": [
    "**Answer: A good summary statistic should capture both spatial localization and temporal activity. I also experimented with the range (max - min) and standard deviation. The range image revealed neurons with bursty or sporadic activity, while standard deviation provided a clearer representation of general fluctuation. These results confirm that temporal variability-based statistics are better for identifying functionally relevant regions.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cef31f",
   "metadata": {},
   "source": [
    "**Problem 3a**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253ee09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "\n",
    "# Load and normalize summary image\n",
    "summary_img = np.var(tiff.imread('/Users/mananbhatt/Downloads/TEST_MOVIE_00001-small.tif'), axis=0)\n",
    "summary_img_norm = (summary_img - np.min(summary_img)) / (np.max(summary_img) - np.min(summary_img))\n",
    "summary_img_8bit = (summary_img_norm * 255).astype(np.uint8)\n",
    "\n",
    "# Resize for display\n",
    "display_img = cv2.resize(summary_img_8bit, (512, 512))\n",
    "clicked_coords = []\n",
    "\n",
    "# Callback\n",
    "def click_event(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN and len(clicked_coords) < 5:\n",
    "        clicked_coords.append((x, y))\n",
    "        print(f\"Clicked: {len(clicked_coords)} -> x={x}, y={y}\")\n",
    "        cv2.circle(display_img, (x, y), 3, (255, 0, 0), -1)\n",
    "        cv2.imshow(\"Click 5 seed points\", display_img)\n",
    "\n",
    "cv2.namedWindow(\"Click 5 seed points\")\n",
    "cv2.setMouseCallback(\"Click 5 seed points\", click_event)\n",
    "\n",
    "# Manual polling loop — auto exit after 5 clicks\n",
    "while True:\n",
    "    cv2.imshow(\"Click 5 seed points\", display_img)\n",
    "    if len(clicked_coords) >= 5:\n",
    "        break\n",
    "    key = cv2.waitKey(10)\n",
    "    if key == 27:  # ESC to exit early\n",
    "        print(\"Manual exit\")\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Scale back to original coordinates\n",
    "orig_h, orig_w = summary_img.shape\n",
    "scale_x = orig_w / 512\n",
    "scale_y = orig_h / 512\n",
    "scaled_coords = [(int(x * scale_x), int(y * scale_y)) for (x, y) in clicked_coords]\n",
    "\n",
    "print(\"Final scaled seed coordinates (x, y):\", scaled_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dee36dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.draw import disk\n",
    "import tifffile as tiff\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and normalize summary image\n",
    "summary_img = np.var(tiff.imread('/Users/mananbhatt/Downloads/TEST_MOVIE_00001-small.tif'), axis=0)\n",
    "summary_img_norm = (summary_img - np.min(summary_img)) / (np.max(summary_img) - np.min(summary_img))\n",
    "\n",
    "# Seeds: scaled_coords from your OpenCV selection\n",
    "# e.g., scaled_coords = [(356, 56), (344, 269), (416, 399), (173, 484), (117, 146)]\n",
    "roi_masks = []\n",
    "radius = 11  # radius of circular ROI in pixels\n",
    "\n",
    "for i, (x, y) in enumerate(scaled_coords):\n",
    "    mask = np.zeros_like(summary_img_norm, dtype=bool)\n",
    "    rr, cc = disk((y, x), radius, shape=summary_img.shape)\n",
    "    mask[rr, cc] = True\n",
    "    roi_masks.append(mask)\n",
    "\n",
    "    # Visualize the mask\n",
    "    masked_img = np.zeros_like(summary_img_norm)\n",
    "    masked_img[mask] = summary_img_norm[mask]\n",
    "\n",
    "    print(f\"ROI {i+1}: seed=({x},{y}), mask pixels={np.sum(mask)}\")\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(masked_img, cmap='plasma')\n",
    "    plt.title(f'Circular ROI {i + 1}')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7c1751",
   "metadata": {},
   "source": [
    "**Problem 3b**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8002f212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skimage.measure import find_contours\n",
    "\n",
    "# Use the same summary image used for ROI creation\n",
    "summary_img = np.var(tiff.imread('/Users/mananbhatt/Downloads/TEST_MOVIE_00001-small.tif'), axis=0)\n",
    "summary_img_norm = (summary_img - np.min(summary_img)) / (np.max(summary_img) - np.min(summary_img))\n",
    "\n",
    "# Overlay each ROI mask on the summary image\n",
    "for idx, mask in enumerate(roi_masks):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(summary_img_norm, cmap='gray')\n",
    "    contours = find_contours(mask, level=0.5)\n",
    "\n",
    "    for contour in contours:\n",
    "        plt.plot(contour[:, 1], contour[:, 0], color='red', linewidth=1.5)\n",
    "\n",
    "    plt.title(f'ROI {idx+1} - Mask Overlay')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253df36d",
   "metadata": {},
   "source": [
    "**Problem 4a**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6ae919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the original motion-corrected video\n",
    "video = tiff.imread('/Users/mananbhatt/Downloads/TEST_MOVIE_00001-small.tif')  # shape: [T, H, W]\n",
    "\n",
    "# Extract time-traces\n",
    "traces = []\n",
    "\n",
    "for idx, mask in enumerate(roi_masks):\n",
    "    trace = [np.mean(frame[mask]) for frame in video]\n",
    "    traces.append(trace)\n",
    "\n",
    "    # Plot time-trace\n",
    "    plt.figure(figsize=(6, 2))\n",
    "    plt.plot(trace, label=f'ROI {idx+1}')\n",
    "    plt.title(f'Time-Trace for ROI {idx+1}')\n",
    "    plt.xlabel('Frame')\n",
    "    plt.ylabel('Fluorescence')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd482b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation\n",
    "import matplotlib as mpl\n",
    "from IPython.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "roi_index = 2\n",
    "trace = traces[roi_index]\n",
    "mask = roi_masks[roi_index]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(6, 6))\n",
    "im = ax1.imshow(video[0], cmap='gray')\n",
    "contour_lines = []\n",
    "\n",
    "# Draw ROI contours on the first frame (initially)\n",
    "contours = find_contours(mask, level=0.5)\n",
    "for contour in contours:\n",
    "    line, = ax1.plot(contour[:, 1], contour[:, 0], color='red', linewidth=1.2)\n",
    "    contour_lines.append(line)\n",
    "\n",
    "# Plot trace\n",
    "line_trace, = ax2.plot([], [], lw=2)\n",
    "ax2.set_xlim(0, len(trace))\n",
    "ax2.set_ylim(np.min(trace), np.max(trace))\n",
    "ax2.set_title(f\"Time-trace for ROI {roi_index+1}\")\n",
    "ax2.set_xlabel(\"Frame\")\n",
    "ax2.set_ylabel(\"Fluorescence\")\n",
    "\n",
    "def update(frame_num):\n",
    "    im.set_array(video[frame_num])\n",
    "    line_trace.set_data(np.arange(frame_num + 1), trace[:frame_num + 1])\n",
    "    return [im, line_trace] + contour_lines\n",
    "\n",
    "ani = animation.FuncAnimation(fig, update, frames=len(video), interval=10, blit=True)\n",
    "mpl.rcParams['animation.embed_limit'] = 100  # allow bigger animations\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23ea0dd",
   "metadata": {},
   "source": [
    "**Answer: Yes, the extracted time-traces can reflect the actual neural activity captured in the calcium imaging video — provided that the ROIs used are accurate and well-localized. These traces are intended to represent the temporal dynamics of fluorescence changes within each ROI, which in turn correlate with neuronal calcium activity.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a2a596",
   "metadata": {},
   "source": [
    "**Problem 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ecc3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# video shape: [T, H, W] → reshape to [pixels, time]\n",
    "T, H, W = video.shape\n",
    "X = video.reshape(T, H * W).T  # shape: [pixels, time]\n",
    "print(f\"Data matrix shape: {X.shape}\")  # (pixels, time)\n",
    "print(f\"Video shape: {video.shape}  [frames, height, width]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ad7048",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set number of PCA components\n",
    "n_components = 20\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=n_components)\n",
    "pca_components = pca.fit_transform(X)  \n",
    "pca_maps = pca_components.T.reshape(n_components, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a6e885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 10 PCA spatial components \n",
    "fig, axs = plt.subplots(1, 10, figsize=(15, 3))\n",
    "for i in range(10):\n",
    "    axs[i].imshow(pca_maps[i], cmap='gray')\n",
    "    axs[i].set_title(f'PC {i+1}')\n",
    "    axs[i].axis('off')\n",
    "plt.suptitle('PCA Spatial Maps')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7faa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 20 PCA spatial components \n",
    "fig, axs = plt.subplots(2, 10, figsize=(20, 5))\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i in range(n_components):\n",
    "    axs[i].imshow(pca_maps[i], cmap='gray')\n",
    "    axs[i].set_title(f'PC {i+1}')\n",
    "    axs[i].axis('off')\n",
    "\n",
    "plt.suptitle('PCA Spatial Maps (20 Components)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f52fec",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "1. PCA Spatial maps often represent mixtures of multiple neurons or global patterns.\n",
    "2. Time-traces that capture directions of high variance.\n",
    "\n",
    "\n",
    "Upon changing the components: \n",
    "1. Fewer components capture global fluctuations.\n",
    "2. Increasing components introduces more detail but can include noise or redundant features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672a212a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "n_components = 20\n",
    "nmf = NMF(n_components=n_components, init='random', random_state=0, max_iter=500)\n",
    "W = nmf.fit_transform(X)           \n",
    "H_matrix = nmf.components_         \n",
    "nmf_maps = W.T.reshape(n_components, video.shape[1], video.shape[2])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4317eff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot NMF spatial maps for 10 components\n",
    "fig, axs = plt.subplots(1, 10, figsize=(20, 3))\n",
    "for i in range(10):\n",
    "    axs[i].imshow(nmf_maps[i], cmap='hot')\n",
    "    axs[i].set_title(f'NMF {i+1}')\n",
    "    axs[i].axis('off')\n",
    "plt.suptitle('NMF Spatial Maps')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6c2d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot NMF spatial maps for 20 components\n",
    "fig, axs = plt.subplots(2, 10, figsize=(15, 3))\n",
    "axs = axs.ravel()\n",
    "for i in range(20):\n",
    "    axs[i].imshow(nmf_maps[i], cmap='hot')\n",
    "    axs[i].set_title(f'NMF {i+1}')\n",
    "    axs[i].axis('off')\n",
    "plt.suptitle('NMF Spatial Maps')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962d5515",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "Yes, NMF (Non-negative Matrix Factorization) is highly dependent on the rank of decomposition\n",
    "\n",
    "\n",
    "1. Sparse spatial maps.\n",
    "2. Time-traces that are strictly non-negative.\n",
    "\n",
    "Upon changing the number of components: \n",
    "\n",
    "1. Too few components may combine multiple neurons.\n",
    "2. Too many components may result in overfitting or component splitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a0a60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FastICA\n",
    "\n",
    "n_components = 20\n",
    "video_height, video_width = video.shape[1], video.shape[2]\n",
    "\n",
    "ica = FastICA(n_components=n_components, random_state=0)\n",
    "ica_components = ica.fit_transform(X)  # shape: (pixels, n_components)\n",
    "ica_maps = ica_components.T.reshape(n_components, video_height, video_width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9e920a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot 10 ICA spatial maps\n",
    "fig, axs = plt.subplots(1, 10, figsize=(15, 3))\n",
    "for i in range(10):\n",
    "    axs[i].imshow(ica_maps[i], cmap='grey')\n",
    "    axs[i].set_title(f'ICA {i+1}')\n",
    "    axs[i].axis('off')\n",
    "plt.suptitle('ICA Spatial Maps')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c92e5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 20 ICA spatial maps\n",
    "fig, axs = plt.subplots(2, 10, figsize=(20, 3))\n",
    "axs = axs.ravel()\n",
    "for i in range(n_components):\n",
    "    axs[i].imshow(ica_maps[i], cmap='grey')\n",
    "    axs[i].set_title(f'ICA {i+1}')\n",
    "    axs[i].axis('off')\n",
    "plt.suptitle('ICA Spatial Maps')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429c65da",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "1. Focused spatial maps that can align with individual neurons.\n",
    "2. Time-traces that may resemble spike trains.\n",
    "\n",
    "Effect of changing n_components:\n",
    "1. Too few components may miss relevant neurons.\n",
    "2. Too many components may extract noise or break apart true signals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b311b37",
   "metadata": {},
   "source": [
    "**Some trial efforts to further analyse what individual components of PCA, NMF, ICA are doing and representing.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fe44e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(pca_maps[0]))\n",
    "print((pca_maps.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b8724d",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 5000  # tweak this as needed\n",
    "binary_roi = pca_maps[0] > threshold\n",
    "\n",
    "plt.imshow(summary_img_norm, cmap='gray')\n",
    "plt.contour(binary_roi, colors='red')\n",
    "plt.title(\"Extracted ROI from PCA Component\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ec7f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.2  # tweak this as needed\n",
    "binary_roi = nmf_maps[0] > threshold\n",
    "\n",
    "plt.imshow(summary_img_norm, cmap='gray')\n",
    "plt.contour(binary_roi, colors='red')\n",
    "plt.title(\"Extracted ROI from NMF Component\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34a7280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.T is shape [time, pixels]\n",
    "ica = FastICA(n_components=n_components, random_state=0)\n",
    "S = ica.fit_transform(X.T)  # shape: [time, components]\n",
    "A = ica.mixing_             # shape: [pixels, components]\n",
    "\n",
    "ica_spatial_maps = A.T.reshape(n_components, video_height, video_width)\n",
    "ica_time_traces = S.T  # shape: [components, time]\n",
    "\n",
    "# Time-trace plot\n",
    "plt.figure(figsize=(10, 4))\n",
    "for i in range(n_components):\n",
    "    plt.plot(ica_time_traces[i], label=f'ICA {i+1}')\n",
    "plt.xlabel(\"Frame\")\n",
    "plt.ylabel(\"Activity\")\n",
    "plt.title(\"ICA Component Time-Traces\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Example spatial map\n",
    "plt.figure()\n",
    "plt.imshow(ica_spatial_maps[0], cmap='gray')\n",
    "plt.title(\"ICA Spatial Map 1\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5b3cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import remove_small_objects\n",
    "from skimage.measure import label\n",
    "\n",
    "component_idx = 2  # Choose the one that looks neuron-like\n",
    "spatial_map = ica_spatial_maps[component_idx]\n",
    "\n",
    "# Normalize the map (optional but recommended)\n",
    "spatial_map_norm = (spatial_map - np.min(spatial_map)) / (np.max(spatial_map) - np.min(spatial_map))\n",
    "\n",
    "# Threshold\n",
    "binary_mask = spatial_map_norm > 0.3  # adjust threshold between 0.2 – 0.5 based on image\n",
    "binary_mask = remove_small_objects(binary_mask, min_size=30)\n",
    "\n",
    "# Label regions (optional if you want the largest blob only)\n",
    "labeled = label(binary_mask)\n",
    "\n",
    "\n",
    "plt.imshow(spatial_map_norm, cmap='gray')\n",
    "plt.contour(binary_mask, colors='red')\n",
    "plt.title(f\"ICA ROI {component_idx+1}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "roi_trace = [np.mean(frame[binary_mask]) for frame in video]\n",
    "\n",
    "plt.figure(figsize=(6, 2))\n",
    "plt.plot(roi_trace)\n",
    "plt.title(f\"Fluorescence Trace of ICA ROI {component_idx+1}\")\n",
    "plt.xlabel(\"Frame\")\n",
    "plt.ylabel(\"Mean Intensity\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67da2d58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
